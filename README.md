# Introduction to Machine Learning & Deep Learning

## Description

The term machine learning or statistical learning refers to the science of automated detection of patterns in data. It has been widely used in tasks that require information extraction from large data sets. Examples of tasks include SPAM detection, fraudulent credit card transaction detection, face recognition by digital cameras, and voice commands recognition by personal assistance on smart-phones. Machine learning is also widely used in scientific domains such as Bioinformatics, medicine, and astronomy. One characteristic of all these applications is that a human developer cannot provide an explicit and detailed specification of how these tasks should be executed, due to the complexity of the patterns that need to be detected.

## Objectives

This course provides a thorough grounding in the methods, techniques, and algorithms of machine learning. In the end of this course, the students should be able to describe the main concepts underlying machine learning, including for instance: 
   * (a) what is learning
   * (b) how can a machine learning
   * (c) what kind of problems can be solved by using machine learning approaches 
   * (d) how to formalize them as a machine learning problem, and 
   * (e) how to compare and evaluate the performance of different machine learning
   * (f) apply machine learning methods into different use cases, using Python, Pandas, scikit-learn, among others

## Textbooks

* Hastie, T., Tibshirani, R., and Friedman, J. (2016). [The Elements of Statistical Learning: Data Mining, Inference, and Prediction](http://web.stanford.edu/~hastie/ElemStatLearn/). Springer, 2nd edition
* Daum√© III, H. (2017). [A Course in Machine Learning](http://ciml.info/dl/v0_99/ciml-v0_99-all.pdf). Self-published, 2nd edition
* Murphy, K. P. (2012). [Machine learning: a probabilistic perspective](https://www.cs.ubc.ca/~murphyk/MLbook/). MIT press.
* Bishop, C. M. (2006). [Pattern recognition and machine learning](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf). Springer.
* James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013). [An introduction to statistical learning](http://www-bcf.usc.edu/~gareth/ISL/). Springer
* Goodfellow, I., Bengio, Y., and Courville, A. (2016). [Deep learning](https://www.deeplearningbook.org/). MIT press.
* Valiant, L. (2013). Probably Approximately Correct: Nature's Algorithms for Learning and Prospering in a Complex World. Basic Books, Inc.


## Grading scheme

 * A practical session that will realized in group of two students.
 * One individual project used for the personal evaluation at the end of the course. It must be an IoT use case.

## Lectures

1. Machine Learning 

   * Introduction to machine learning
   * Computational foundations:
       - Using Python, Anaconda, Jupyter Notebooks
       - Scientific Computing with NumPy, SciPy, and Matplotlib
       - Exploratory data analysis (EDA), data processing, and machine learning with [scikit-learn](https://scikit-learn.org/)
       - Reproducible machine learning pipeline with Docker

2. Regression: predicting house prices
   
   * Introduction
   * Regression, gradient descent
   * Assessing performance, error types, and bias/variance trade-off
   * Overfitting, regularized regression, ridge regression
   * Lasso regression, cross-validation

3. Classification: sentiment analysis

   * Introduction
   * Logistic regression
   * Tree-based methods:
      - decision trees
      - overfitting in decision trees
   * Precision, recall, and ROC curve
   * Ensemble methods:
      - Boosting
      - Bagging
      - Random Forests

4. Clustering and similarity: retrieving documents
  
   * Introduction to clustering
   * kNN methods for classification and regression
   * k-means
   * Hierarchical clustering

5. Dimensionality reduction

   * Feature selection and extraction
   * Principal component analysis (PCA)

6. Recommender systems: recommending products

    * Introduction to recommender systems
    * Performance metrics

7. Neural networks

    * Perceptron
    * Multilayer Perceptron 
    * Support Vector Machines (SVM)

8. Deep learning: image classification
  
    * Introduction
    * Single and multilayer networks
    * Convolutional neural network (CNN)


## Resources

* [Google Dataset Search](https://toolbox.google.com/datasetsearch)
* [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)
* [Kaggle datasets](https://www.kaggle.com/datasets)
* [Google Colaboratory](https://colab.research.google.com)
* [Jupyter Notebook](https://jupyter.org/)
* [scikit-learn](https://scikit-learn.org/stable/documentation.html)

<!-- 
## Papers
  * Sugimura, P., & Hartl, F. (2018). [Building a Reproducible Machine Learning Pipeline](https://arxiv.org/pdf/1810.04570.pdf). arXiv preprint arXiv:1810.04570. -->